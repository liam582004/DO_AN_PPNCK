{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection For Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Các đặc trưng dữ liệu bạn sử dụng để huấn luyện mô hình học máy có ảnh hưởng lớn đến hiệu suất bạn có thể đạt được. Các đặc trưng không liên quan hoặc liên quan một phần có thể tác động tiêu cực đến hiệu suất mô hình. Chương này trình bày các kỹ thuật lựa chọn đặc trưng tự động trong Python với scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lựa chọn đặc trưng là quá trình tự động chọn những đặc trưng trong dữ liệu đóng góp nhiều nhất vào biến dự đoán. Việc có các đặc trưng không liên quan có thể làm giảm độ chính xác của nhiều mô hình.\n",
    "Ba lợi ích của việc lựa chọn đặc trưng:\n",
    "* **Giảm Overfitting:** Ít dữ liệu dư thừa hơn.\n",
    "* **Cải thiện Độ chính xác:** Ít dữ liệu gây hiểu lầm hơn.\n",
    "* **Giảm Thời gian Huấn luyện:** Ít dữ liệu hơn.\n",
    "Các công thức sau sử dụng bộ dữ liệu Pima Indians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Univariate Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các kiểm định thống kê có thể được sử dụng để chọn những đặc trưng có mối quan hệ mạnh nhất với biến đầu ra. Lớp `SelectKBest` của scikit-learn có thể được sử dụng với một bộ kiểm định thống kê khác nhau để chọn một số lượng đặc trưng cụ thể. Ví dụ dưới đây sử dụng kiểm định chi-bình phương (`chi2`) để chọn 4 đặc trưng tốt nhất.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất đặc trưng với Kiểm định Thống kê Đơn biến (Chi-bình phương cho phân loại)\n",
    "# (Feature Extraction with Univariate Statistical Tests (Chi-squared for classification))\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# load data\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "print(\"Scores for each feature:\")\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(\"\\nSelected features data (first 5 rows):\")\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kết quả hiển thị điểm số cho từng thuộc tính.\n",
    "* 4 thuộc tính được chọn (có điểm cao nhất) là: `plas`, `test`, `mass` và `age`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Recursive Feature Elimination - RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất đặc trưng với RFE (Feature Extraction with RFE)\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load data\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# feature extraction\n",
    "# Tăng max_iter để tránh cảnh báo hội tụ\n",
    "model = LogisticRegression(solver='liblinear') # Có thể thay solver nếu cần\n",
    "# Sử dụng n_features_to_select thay vì số nguyên trực tiếp cho các phiên bản mới hơn\n",
    "rfe = RFE(model, n_features_to_select=3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Principal Component Analysis - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất đặc trưng với PCA (Feature Extraction with PCA)\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# load data\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "print(\"Principal Components:\")\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tầm quan trọng của Đặc trưng với Extra Trees Classifier\n",
    "# (Feature Importance with Extra Trees Classifier)\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# load data\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=7) # Thêm n_estimators và random_state\n",
    "model.fit(X, Y)\n",
    "print(\"Feature Importances:\")\n",
    "print(model.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
