








from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression

filename = 'pima-indians-diabetes.data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']

dataframe = read_csv(filename, names=names)

arr = dataframe.values
X = arr[:, 0:8]
y = arr[:, 8]

kfold = KFold(n_splits=10, random_state=7, shuffle=True)

model = LogisticRegression(max_iter=1000)  
scoring = 'accuracy'
results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)

print(f"Accuracy: {results.mean()*100.0:.3f}% ({results.std()*100.0:.3f}%)")






from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression

filename = 'pima-indians-diabetes.data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']

dataframe = read_csv(filename, names=names)

arr = dataframe.values
X = arr[:, 0:8]
y = arr[:, 8]

kfold = KFold(n_splits=10, random_state=7, shuffle=True)

model = LogisticRegression(max_iter=1000)  
scoring = 'neg_log_loss'
results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)
print(f"Logloss: {results.mean()*100.0:.3f}% ({results.std()*100.0:.3f}%)")





from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression

filename = 'pima-indians-diabetes.data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']

dataframe = read_csv(filename, names=names)

arr = dataframe.values
X = arr[:, 0:8]
y = arr[:, 8]

kfold = KFold(n_splits=10, random_state=7, shuffle=True)

model = LogisticRegression(max_iter=1000)  
scoring = 'roc_auc'
results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)
print(f"AUC: {results.mean()*100.0:.3f}% ({results.std()*100.0:.3f}%)")





from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix

filename = 'pima-indians-diabetes.data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']

dataframe = read_csv(filename, names=names)

arr = dataframe.values
X = arr[:, 0:8]
y = arr[:, 8]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7)

model = LogisticRegression(max_iter=200)  
model.fit(X_train, y_train)

predicted = model.predict(X_test)

matrix = confusion_matrix(y_test, predicted)
print(matrix)






from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

filename = 'pima-indians-diabetes.data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']

dataframe = read_csv(filename, names=names)

arr = dataframe.values
X = arr[:, 0:8]
y = arr[:, 8]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7)

model = LogisticRegression(max_iter=200)  
model.fit(X_train, y_train)

predicted = model.predict(X_test)

report = classification_report(Y_test, predicted)
print(report)









from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
filename = 'housing.csv'
names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',
'B', 'LSTAT', 'MEDV']
dataframe = read_csv(filename, delim_whitespace=True, names=names)
array = dataframe.values
X = array[:,0:13]
Y = array[:,13]
kfold = KFold(n_splits=10, random_state=None)
model = LinearRegression()
scoring = 'neg_mean_absolute_error'
results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print("MAE: %.3f (%.3f)") % (results.mean(), results.std())











from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
filename = 'housing.csv'
names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',
'B', 'LSTAT', 'MEDV']
dataframe = read_csv(filename, delim_whitespace=True, names=names)
array = dataframe.values
X = array[:,0:13]
Y = array[:,13]
kfold = KFold(n_splits=10, random_state=7)
model = LinearRegression()
scoring = 'r2'
results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print("R^2: %.3f (%.3f)") % (results.mean(), results.std())



